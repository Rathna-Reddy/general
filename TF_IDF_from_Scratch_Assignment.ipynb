{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsnogjXUQu1K"
   },
   "source": [
    "# NOTE:\n",
    "\n",
    "1. Please implement the TFIDf function such that for each word in a sentence, its corresponding tfidf value is assigned. Thus a 4 x 6 sized matrix should be returned where the rows represent sentences and the columns represent words. We wish to keep it simple in the beginning.\n",
    "\n",
    "2. In reality the TFIDF function should return a matrix where the rows represent sentences and the columns represent words (ie: Features). Every sentence vector in this matrix will be 'd' dimensional, where d = number of unique words in the corpus (ie: Vocabulary).\n",
    "Every position/cell in a sentence vector correponds to a particular word in the vocabulary. If the word is not present in the current sentence, we assign a value of 0 to that cell, else we assign the TFIDF value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vrZdUum2xPk"
   },
   "source": [
    "# **Implement TF-IDF from scratch**\n",
    "\n",
    "In this assignment, you will implement TF-IDF vectorization of text from scratch using only Python and inbuilt data structures. You will then verify the correctness of the your implementation using a \"grader\" function/cell (provided by us) which will match your implmentation.\n",
    "\n",
    "The grader fucntion would help you validate the correctness of your code. \n",
    "\n",
    "Please submit the final Colab notebook in the classroom ONLY after you have verified your code using the grader function/cell.\n",
    "\n",
    "**(FAQ) Why bother about implementing a function to compute TF-IDF when it is already available in major libraries?**\n",
    "\n",
    "Ans.\n",
    "1. It helps you improve your coding proficiency.\n",
    "2. It helps you obtain a deeper understanding of the concepts and how it works internally. Knowledge of the internals will also help you debug problems better.\n",
    "3. A lot of product based startups and companies do focus on this in thier interviews to gauge your depth and clarity of understanding along with your programming skills. Hence, most top universities have implementations of some ML algorithms/concepts as mandatory assignments.\n",
    "\n",
    "**NOTE: DO NOT change the \"grader\" functions or code snippets written by us.Please add your code in the suggested locations.**\n",
    "\n",
    "Ethics Code:\n",
    "1. You are welcome to read up online resources to implement the code. \n",
    "2. You can also discuss with your classmates on the implmentation over Slack.\n",
    "3. But, the code you wirte and submit should be yours ONLY. Your code will be compared against other stduents' code and online code snippets to check for plagiarism. If your code is found to be plagiarised, you will be awarded zero-marks for all assignments, which have a 10% wieghtage in the final marks for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZxSRJ4KT3OMw"
   },
   "outputs": [],
   "source": [
    "# Corpus to be used for this assignment\n",
    "\n",
    "corpus = [\n",
    "     'this is the first document mostly',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document here',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aYoKXNsU3nhO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is': 4, 'first': 2, 'document': 3, 'this': 4, 'the': 4, 'mostly': 1, 'second': 1, 'third': 1, 'and': 1, 'one': 1, 'here': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.12, 0.05, 0.23],\n",
       "       [0.  , 0.1 , 0.  , 0.  , 0.23, 0.1 ],\n",
       "       [0.23, 0.  , 0.  , 0.  , 0.23, 0.23],\n",
       "       [0.  , 0.  , 0.  , 0.12, 0.05, 0.23]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def computeTFIDF (corpus):\n",
    "  \"\"\"Given a list of sentences as \"corpus\", return the TF-IDF vectors for all the \n",
    "  sentences in the corpus as a numpy 2D matrix. \n",
    "  \n",
    "  Each row of the 2D matrix must correspond to one sentence \n",
    "  and each column corresponds to a word in the text corpus. \n",
    "  \n",
    "  Please order the rows in the same order as the \n",
    "  sentences in the input \"corpus\". \n",
    "    \n",
    "  Ignore puncutation symbols like comma, fullstop, \n",
    "  exclamation, question-mark etc from the input corpus.\n",
    "  \n",
    "  For e.g, If the corpus contains sentences with these \n",
    "  9 distinct words, ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], \n",
    "  then the first column of the 2D matrix will correpsond to word \"and\", the second column will \n",
    "  correspond to column \"document\" and so on. \n",
    "  \n",
    "  Write this function using only basic Python code, inbuilt Data Structures and  NumPy ONLY.\n",
    "\n",
    "  Implement the code as optimally as possible using the inbuilt data structures of Python.\n",
    "  \"\"\"\n",
    "  ##############################################################\n",
    "  ####   YOUR CODE BELOW  as per the above instructions #######\n",
    "  ##############################################################\n",
    "\n",
    "  #calculate the word frequency in corpus\n",
    "  dictWordFreqInCorpus = {}\n",
    "  for document in corpus:\n",
    "        unique_words = set(document.split())\n",
    "        for word in unique_words:\n",
    "            if word in dictWordFreqInCorpus:\n",
    "                dictWordFreqInCorpus[word] +=1\n",
    "            else:\n",
    "                dictWordFreqInCorpus[word] = 1\n",
    "  print(dictWordFreqInCorpus)\n",
    "\n",
    "  tf_idf_corpus = [] \n",
    "  #calculate Term Frequency and multiply with idf\n",
    "  for document in corpus:\n",
    "        freq = {}\n",
    "        words = document.split()\n",
    "        lstSentence = []\n",
    "        for word in words:\n",
    "            if word in freq:\n",
    "                freq[word] = freq[word]+1\n",
    "            else:\n",
    "                freq[word] = 1\n",
    "        for word in document.split():\n",
    "            tf = freq[word]/len(words)\n",
    "            idf_word = np.log(len(corpus)/dictWordFreqInCorpus[word])\n",
    "            tf_idf = round(tf*idf_word,2)\n",
    "            lstSentence.append(tf_idf)\n",
    "        tf_idf_corpus.append(lstSentence)\n",
    "   \n",
    "  return np.array(tf_idf_corpus)\n",
    "            \n",
    "\n",
    "computeTFIDF(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ_hmMn92bEe"
   },
   "source": [
    "# Grader Cell\n",
    "Please execute the following Grader cell to verify the correctness of your above implementation. This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct, else, it will print \"Failed\". Make sure you get a \"Success\" before you submit the code in the classroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUYmXFjfu53i",
    "outputId": "a5ba688d-3a00-4d8e-a0b5-59f67cd70895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is': 4, 'first': 2, 'document': 3, 'this': 4, 'the': 4, 'mostly': 1, 'second': 1, 'third': 1, 'and': 1, 'one': 1, 'here': 1}\n",
      "******** Success ********\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "## GRADER CELL: Do NOT Change this.\n",
    "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
    "# Else, it will print \"Failed\"\n",
    "###########################################\n",
    "import numpy as np\n",
    "\n",
    "# compute TF-IDF using the computeTFIDF() function\n",
    "X_custom = computeTFIDF(corpus)\n",
    "\n",
    "# Reference grader array - DO NOT MODIFY IT\n",
    "X_grader = np.array(\n",
    "    [[0, 0, 0, 0.12, 0.05, 0.23],\n",
    "     [0, 0.1, 0, 0, 0.23, 0.1],\n",
    "     [0.23, 0, 0, 0, 0.23, 0.23],\n",
    "     [0, 0, 0, 0.12, 0.05, 0.23]]\n",
    "     )\n",
    "\n",
    "# compare X_grader and X_custom\n",
    "comparison = (X_grader == X_custom)\n",
    "isEqual = comparison.all()\n",
    "\n",
    "if isEqual:\n",
    "  print(\"******** Success ********\")\n",
    "else:\n",
    "  print(\"####### Failed #######\")\n",
    "  print(\"\\nX_grader = \\n\\n\", X_grader)\n",
    "  print(\"\\n\",\"*\"*50)\n",
    "  print(\"\\nX_custom = \\n\\n\", X_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate tf-idf and compare the results with sklearn's implememtation\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "class CustomTfidfVectorizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"initializing an empty dictionary to store all the unique terms in corpus\n",
    "        and their idf values, these unique words also form our vocab\"\"\"\n",
    "        self.vocab = {}\n",
    "    \n",
    "    def term_frequency(self, document):\n",
    "        \"\"\"calculate Term Frequency of words/terms in the document\"\"\"\n",
    "        lenOfDoc = len(document)\n",
    "        words = document.split(\" \")\n",
    "        tf_dict = dict(Counter(words))\n",
    "        for word in words:\n",
    "            termFreq = (tf_dict[word]/(lenOfDoc*1.0))\n",
    "            tf_dict[word] = termFreq\n",
    "        return tf_dict\n",
    "            \n",
    "        \n",
    "        \n",
    "    def inverse_doc_frequency(self, corpus):\n",
    "        \"\"\"calculate inverse document frequency of terms/words in the corpus\"\"\"\n",
    "        lCorpus = len(corpus)\n",
    "        idf = {}\n",
    "        for document in corpus:\n",
    "            uWords = set(document.split(\" \"))\n",
    "            for word in uWords:\n",
    "                if word in idf:\n",
    "                    idf[word] += 1\n",
    "                else:\n",
    "                    idf[word] = 1\n",
    "        for word in idf:\n",
    "            idf[word] = 1 + np.log((1+lCorpus)/(1+idf[word]))\n",
    "            \n",
    "        #craeating a voculabulary dictionary to have sorted vocab alphabetically along with idf values\n",
    "        self.vocab = {key : idf[key] for key in sorted(idf)}\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, corpus):\n",
    "        \"\"\"calculate idf values for the terms in corpus\"\"\"\n",
    "        if isinstance(corpus, list):\n",
    "            self.inverse_doc_frequency(corpus)\n",
    "        else:\n",
    "            print(\"invalid input, please pass only list of string as input\")\n",
    "            \n",
    "            \n",
    "    def transform(self, corpus):\n",
    "         #create lists to store the values as sparse matrix\n",
    "        rows = []\n",
    "        columns = []\n",
    "        values = []\n",
    "        \n",
    "        if(isinstance(corpus, list)):\n",
    "            for idx, document in enumerate(tqdm(corpus)):\n",
    "                tf = self.term_frequency(document)\n",
    "                words = document.split(\" \")\n",
    "                \n",
    "                for word, frequency in tf.items():\n",
    "                    if word in self.vocab.keys():\n",
    "                        value = (frequency*(self.vocab[word]))\n",
    "                        \n",
    "                        if value !=0 :\n",
    "                            col_index = list(self.vocab.keys()).index(word)\n",
    "                            rows.append(idx)\n",
    "                            columns.append(col_index)\n",
    "                            values.append(value)\n",
    "                \n",
    "            #Creating a final sparse matrix with the help of scipy\n",
    "            sparse_matrix = csr_matrix((values,(rows, columns)), shape = (len(corpus), len(self.vocab)))\n",
    "            \n",
    "            #Apply L2 normalization on output\n",
    "            output = normalize(sparse_matrix, norm = 'l2', axis=1, copy=True, return_norm=False)\n",
    "            \n",
    "            return output\n",
    "                \n",
    "        else:\n",
    "            print(\"invalid input, please pass only list of strings as input\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 4/4 [00:00<00:00, 8351.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#calling the custom written TF-IDF function\n",
    "vect = CustomTfidfVectorizer()\n",
    "vect.fit(corpus)\n",
    "custom = vect.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1.916290731874155,\n",
       " 'document': 1.2231435513142097,\n",
       " 'first': 1.5108256237659907,\n",
       " 'here': 1.916290731874155,\n",
       " 'is': 1.0,\n",
       " 'mostly': 1.916290731874155,\n",
       " 'one': 1.916290731874155,\n",
       " 'second': 1.916290731874155,\n",
       " 'the': 1.0,\n",
       " 'third': 1.916290731874155,\n",
       " 'this': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#custom implementation vocab and their corresponding idf values\n",
    "vect.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.37835697 0.46734613 0.         0.30933162 0.59276931\n",
      "  0.         0.         0.30933162 0.         0.30933162]]\n"
     ]
    }
   ],
   "source": [
    "#custom implementation tf-idf valules\n",
    "print(custom[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.3783569705698033\n",
      "  (0, 2)\t0.46734613075721393\n",
      "  (0, 4)\t0.3093316153801217\n",
      "  (0, 5)\t0.592769307628588\n",
      "  (0, 8)\t0.3093316153801217\n",
      "  (0, 10)\t0.3093316153801217\n",
      "  (1, 1)\t0.02629790433498686\n",
      "  (1, 4)\t0.3870046794762219\n",
      "  (1, 7)\t0.7416134804722121\n",
      "  (1, 8)\t0.3870046794762219\n",
      "  (1, 10)\t0.3870046794762219\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 4)\t0.267103787642168\n",
      "  (2, 6)\t0.511848512707169\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (2, 9)\t0.511848512707169\n",
      "  (2, 10)\t0.267103787642168\n",
      "  (3, 1)\t0.37835697056980316\n",
      "  (3, 2)\t0.4673461307572138\n",
      "  (3, 3)\t0.5927693076285879\n",
      "  (3, 4)\t0.30933161538012166\n",
      "  (3, 8)\t0.30933161538012166\n",
      "  (3, 10)\t0.30933161538012166\n"
     ]
    }
   ],
   "source": [
    "#total sparse matrix of custom implementation\n",
    "print(custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "skl = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn TFIDF Vectorizer Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'here', 'is', 'mostly', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn TFIDF Vectorizer - IDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.91629073 1.22314355 1.51082562 1.91629073 1.         1.91629073\n",
      " 1.91629073 1.91629073 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn tfidf values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.37835697 0.46734613 0.         0.30933162 0.59276931\n",
      "  0.         0.         0.30933162 0.         0.30933162]]\n"
     ]
    }
   ],
   "source": [
    "print(skl[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total sparse matrix of sklearn tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.592769307628588\n",
      "  (0, 1)\t0.3783569705698032\n",
      "  (0, 2)\t0.4673461307572138\n",
      "  (0, 8)\t0.30933161538012166\n",
      "  (0, 4)\t0.30933161538012166\n",
      "  (0, 10)\t0.30933161538012166\n",
      "  (1, 7)\t0.5386476208856763\n",
      "  (1, 1)\t0.6876235979836938\n",
      "  (1, 8)\t0.281088674033753\n",
      "  (1, 4)\t0.281088674033753\n",
      "  (1, 10)\t0.281088674033753\n",
      "  (2, 6)\t0.511848512707169\n",
      "  (2, 9)\t0.511848512707169\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (2, 4)\t0.267103787642168\n",
      "  (2, 10)\t0.267103787642168\n",
      "  (3, 3)\t0.592769307628588\n",
      "  (3, 1)\t0.3783569705698032\n",
      "  (3, 2)\t0.4673461307572138\n",
      "  (3, 8)\t0.30933161538012166\n",
      "  (3, 4)\t0.30933161538012166\n",
      "  (3, 10)\t0.30933161538012166\n"
     ]
    }
   ],
   "source": [
    "print(skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
